# LLM Prompt Engineering Lab

This project demonstrates four core prompting techniques using the **Ollama** library and **Llama 3.2**. It serves as a guide for developers looking to optimize their interactions with local LLMs.

## üß™ Included Techniques
* **Zero-Shot Prompting**: Asking the model to perform a task without any prior examples.
* **One-Shot Prompting**: Providing a single example to establish the desired output format.
* **Few-Shot Prompting**: Using multiple examples to guide the model through complex patterns.
* **Chain-of-Thought (CoT)**: Prompting the model to break down its reasoning into logical steps before providing a final answer.

## üõ†Ô∏è Requirements
* [Ollama](https://ollama.com/)
* Python library: `pip install ollama`

## üöÄ How to Run
1. Ensure Ollama is running locally.
2. Run the script: `python diff_prmnt.py`
